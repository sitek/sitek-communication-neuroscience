[
  {
    "objectID": "talk.html#a-systems-level-approach-to-human-speech-neuroscience",
    "href": "talk.html#a-systems-level-approach-to-human-speech-neuroscience",
    "title": "Imaging the neural systems underlying human communication",
    "section": "A systems-level approach to human speech neuroscience",
    "text": "A systems-level approach to human speech neuroscience"
  },
  {
    "objectID": "talk.html#a-systems-level-approach-to-human-speech-neuroscience-1",
    "href": "talk.html#a-systems-level-approach-to-human-speech-neuroscience-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "A systems-level approach to human speech neuroscience",
    "text": "A systems-level approach to human speech neuroscience\n\n\n\n\n\n\nSensory behavior - how we use auditory information to learn about and act in the world"
  },
  {
    "objectID": "talk.html#a-systems-level-approach-to-human-speech-neuroscience-2",
    "href": "talk.html#a-systems-level-approach-to-human-speech-neuroscience-2",
    "title": "Imaging the neural systems underlying human communication",
    "section": "A systems-level approach to human speech neuroscience",
    "text": "A systems-level approach to human speech neuroscience\n\n\n\n\n\n\nIdentifying brain structure and function in atypical communication, and learning new questions to ask neuroscience\n(not necessarily to diagnose, but rather to identify neural characteristics associated with a disorder, and perhaps to optimize treatment)\nEstablished collaborations: - Functional and structural connectivity in persistent developmental stuttering (Sitek et al., 2016; ongoing Pitt collaboration) - Speech feedback control in individuals with cerebellar stroke (R01 Co-Investigator; PI: Bohland) - White matter pathways in autism spectrum disorder (Boets et al., 2018) - White matter integrity in sensorineural hearing loss (Tarabichi et al., 2018)"
  },
  {
    "objectID": "talk.html#first-steps-linguistics-and-cognitive-science-undergraduate-at-uc-berkeley",
    "href": "talk.html#first-steps-linguistics-and-cognitive-science-undergraduate-at-uc-berkeley",
    "title": "Imaging the neural systems underlying human communication",
    "section": "First steps: Linguistics and Cognitive Science Undergraduate at UC Berkeley",
    "text": "First steps: Linguistics and Cognitive Science Undergraduate at UC Berkeley\n\n\n\n\n\n\n\nSitek & Johnson (2012 Chicago Linguistic Society). “Ipsilateral and contralateral phonetic context effects”."
  },
  {
    "objectID": "talk.html#brain-imaging-research-assistant-at-ucsfsan-francisco-va-medical-center",
    "href": "talk.html#brain-imaging-research-assistant-at-ucsfsan-francisco-va-medical-center",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Brain imaging research assistant at UCSF/San Francisco VA Medical Center",
    "text": "Brain imaging research assistant at UCSF/San Francisco VA Medical Center\n\n\n\n\n\n\n\nSitek et al. (2013). “Auditory cortex processes variation in our own speech”."
  },
  {
    "objectID": "talk.html#phd-in-speech-and-hearing-bioscience-and-technology-at-harvardmit",
    "href": "talk.html#phd-in-speech-and-hearing-bioscience-and-technology-at-harvardmit",
    "title": "Imaging the neural systems underlying human communication",
    "section": "PhD in Speech and Hearing Bioscience and Technology at Harvard/MIT",
    "text": "PhD in Speech and Hearing Bioscience and Technology at Harvard/MIT\n\n\n\n\n\n\n\nNRSA F31 (2016–2018); Sitek et al. (2016), Connectivity and stuttering severity; Sitek and Gulban et al. (2019), “Mapping the human subcortical auditory system”."
  },
  {
    "objectID": "talk.html#postdoctoral-research-in-neuroscience-at-baylor-college-of-medicine",
    "href": "talk.html#postdoctoral-research-in-neuroscience-at-baylor-college-of-medicine",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Postdoctoral research in Neuroscience at Baylor College of Medicine",
    "text": "Postdoctoral research in Neuroscience at Baylor College of Medicine\n\n\n\n\n\n\n\nUltra-high field 9.4 Tesla functional MRI of the human midbrain (collaborative CRCNS with Tübingen)"
  },
  {
    "objectID": "talk.html#research-scientist-in-communication-science-and-disorders-at-the-university-of-pittsburgh",
    "href": "talk.html#research-scientist-in-communication-science-and-disorders-at-the-university-of-pittsburgh",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Research Scientist in Communication Science and Disorders at the University of Pittsburgh",
    "text": "Research Scientist in Communication Science and Disorders at the University of Pittsburgh\n\n\n\n\n\n\n\nNIH K01 (2022–2027); Sitek et al. (2022), Structural connectivity of human inferior colliculus"
  },
  {
    "objectID": "talk.html#now-research-assistant-professor-at-northwestern-university",
    "href": "talk.html#now-research-assistant-professor-at-northwestern-university",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Now: Research Assistant Professor at Northwestern University",
    "text": "Now: Research Assistant Professor at Northwestern University\n\n\n\n\n\n\n\nNIH R21 (2025–2028); auditory learning and auditory–motor interactions"
  },
  {
    "objectID": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship",
    "href": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Widening perspectives and expanding opportunities through teaching and mentorship",
    "text": "Widening perspectives and expanding opportunities through teaching and mentorship"
  },
  {
    "objectID": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-1",
    "href": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Widening perspectives and expanding opportunities through teaching and mentorship",
    "text": "Widening perspectives and expanding opportunities through teaching and mentorship\n\n\n\nSpeech Production (MIT/Harvard Teaching Assistant)\n\nLecture on articulatory phonetics\nBok Teaching Center Award for Teaching Excellence\n\nThe human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)\nSubcortical contributions to language (UT Dallas guest lecture)\nCommunicating Science (Northwestern CSD PhD program)\n\nTailoring your written/oral/visual presentations to your specific audience\nBuilds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)\n73% of students rated the course at the highest possible level\n\nNorthwestern PhD committee/co-mentorship\n\nSerena Mon (CSD)\nMichelle Medina (BME; Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep)\n\nNorthwestern undergraduate mentorship\n\nGabby Butler (Cognitive Science; Butler, …, Sitek, in prep)\nMax Chen (Cognitive Science/Computer Science)\n\nPitt AuD/undergraduate co-mentorship\n\nAs well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship"
  },
  {
    "objectID": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-2",
    "href": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-2",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Widening perspectives and expanding opportunities through teaching and mentorship",
    "text": "Widening perspectives and expanding opportunities through teaching and mentorship\n\n\n\nSpeech Production (MIT/Harvard Teaching Assistant)\n\nLecture on articulatory phonetics\nBok Teaching Center Award for Teaching Excellence\n\nThe human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)\nSubcortical contributions to language (UT Dallas guest lecture)\nCommunicating Science (Northwestern CSD PhD program)\n\nTailoring your written/oral/visual presentations to your specific audience\nBuilds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)\n73% of students rated the course at the highest possible level\n\nNorthwestern PhD committee/co-mentorship\n\nSerena Mon (CSD)\nMichelle Medina (BME; Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep)\n\nNorthwestern undergraduate mentorship\n\nGabby Butler (Cognitive Science; Butler, …, Sitek, in prep)\nMax Chen (Cognitive Science/Computer Science)\n\nPitt AuD/undergraduate co-mentorship\n\nAs well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship"
  },
  {
    "objectID": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-3",
    "href": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-3",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Widening perspectives and expanding opportunities through teaching and mentorship",
    "text": "Widening perspectives and expanding opportunities through teaching and mentorship\n\n\n\nSpeech Production (MIT/Harvard Teaching Assistant)\n\nLecture on articulatory phonetics\nBok Teaching Center Award for Teaching Excellence\n\nThe human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)\nSubcortical contributions to language (UT Dallas guest lecture)\nCommunicating Science (Northwestern CSD PhD program)\n\nTailoring your written/oral/visual presentations to your specific audience\nBuilds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)\n73% of students rated the course at the highest possible level\n\nNorthwestern PhD committee/co-mentorship\n\nSerena Mon (CSD)\nMichelle Medina (BME; Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep)\n\nNorthwestern undergraduate mentorship\n\nGabby Butler (Cognitive Science; Butler, …, Sitek, in prep)\nMax Chen (Cognitive Science/Computer Science)\n\nPitt AuD/undergraduate co-mentorship\n\nAs well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship"
  },
  {
    "objectID": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-4",
    "href": "talk.html#widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-4",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Widening perspectives and expanding opportunities through teaching and mentorship",
    "text": "Widening perspectives and expanding opportunities through teaching and mentorship\n\n\n\nSpeech Production (MIT/Harvard Teaching Assistant)\n\nLecture on articulatory phonetics\nBok Teaching Center Award for Teaching Excellence\n\nThe human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)\nSubcortical contributions to language (UT Dallas guest lecture)\nCommunicating Science (Northwestern CSD PhD program)\n\nTailoring your written/oral/visual presentations to your specific audience\nBuilds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)\n73% of students rated the course at the highest possible level\n\nNorthwestern PhD committee/co-mentorship\n\nSerena Mon (CSD)\nMichelle Medina (BME; Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep)\n\nNorthwestern undergraduate mentorship\n\nGabby Butler (Cognitive Science; Butler, …, Sitek, in prep)\nMax Chen (Cognitive Science/Computer Science)\n\nPitt AuD/undergraduate co-mentorship\n\nAs well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship"
  },
  {
    "objectID": "talk.html#research-contributions-to-communication-neuroscience",
    "href": "talk.html#research-contributions-to-communication-neuroscience",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Research contributions to communication neuroscience",
    "text": "Research contributions to communication neuroscience\n\n\nMapping the human subcortical auditory system\n\nAnatomy (Sitek & Gulban et al., 2019)\nFunction (Sitek & Gulban et al., 2019; Medina, Sitek, et al., submitted preprint)\nStructural and functional connectivity (Sitek & Gulban et al., 2019; Sitek et al., 2022; Chandra & Sitek et al., 2024)\nNeurovascular organization (Xu et al., ISMRM 2025; Xu, …, S. Bollmann, Sitek, in prep.)\n\n\nBehavior of the human auditory system\n\nAuditory categorization in the human brain (Sitek et al., in re-review; Llanos & Sitek et al., in re-review; Deschamps, Sitek, et al., in prep.)\nAuditory–motor interactions across the auditory pathway (Butler, …, Sitek, in prep.)\nTop–down modulation of predicted sound processing across the auditory pathway (Ara et al., 2024)\nSpeech-in-noise processing in the developing brain (Sitek et al., SNL 2025; in prep.)\n\n\n\n\nSpeaker notes go here.\n\n\nThis work is actively supported by K01-DC019421 and R21-DC022906 and was previously supported by F31-DC015695."
  },
  {
    "objectID": "talk.html#whats-special-about-the-auditory-system",
    "href": "talk.html#whats-special-about-the-auditory-system",
    "title": "Imaging the neural systems underlying human communication",
    "section": "What’s special about the auditory system?",
    "text": "What’s special about the auditory system?\n\n\n\n\n\n\n\nKaas & Hackett (2000)\n\n\n\n\n\n\n\n\n\nVan Essen et al. (1992)"
  },
  {
    "objectID": "talk.html#whats-special-about-the-auditory-system-1",
    "href": "talk.html#whats-special-about-the-auditory-system-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "What’s special about the auditory system?",
    "text": "What’s special about the auditory system?\n\n\n\n\n\n\nKaas & Hackett (2000)\n\n\n\n\n\n\n\nVan Essen et al. (1992)\n\n\n\n\n\n\nSo why should we focus on the subcortical parts of the auditory system? I said that those are the harder parts to investigate with MRI, right? Well, there’s actually a lot going on in the brainstem and thalamus, especially in the auditory system. Two examples from primates show differences between the wiring of the auditory and visual systems. In the auditory system, the first 5 layers of the system are subcortical, and with some cross-talk between them, so some processing can pass through even more structures. Meanwhile, in the visual system, there’s just one or two stages before hitting primary sensory cortex. Indeed, a lot of processing is already done by the retina itself. With other features extracted later in successively higher levels of visual cortex. Whereas in the auditory system, there’s some basic frequency and sound level information pulled out by the cochlea, but some other features like location of sound sources are extracted in the brainstem.\nBUT THE VAST MAJORITY OF OUR KNOWLEDGE COMES FROM ANIMAL STUDIES"
  },
  {
    "objectID": "talk.html#the-human-subcortical-auditory-system",
    "href": "talk.html#the-human-subcortical-auditory-system",
    "title": "Imaging the neural systems underlying human communication",
    "section": "The human subcortical auditory system",
    "text": "The human subcortical auditory system\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBut: small, deep brain structures are challenging to image.\n\n\nAcross human behaviors, studying the brainstem is challenging. - In vivo MRI limited by: - high resolution needed for small structures - decreased signal as voxels get smaller - decreased signal in brainstem - Limited spatial information from EEG, MEG - Some human histology studies (nuclei) - Tracer studies (connections) only in animal models"
  },
  {
    "objectID": "talk.html#post-mortem-anatomical-localization",
    "href": "talk.html#post-mortem-anatomical-localization",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Post mortem anatomical localization",
    "text": "Post mortem anatomical localization\n\n\n\n\n\n\n\n\n\n\n\n\nSpeaker notes go here.\n\n\nSitek and Gulban et al. (2019 eLife)"
  },
  {
    "objectID": "talk.html#d-subcortical-atlases",
    "href": "talk.html#d-subcortical-atlases",
    "title": "Imaging the neural systems underlying human communication",
    "section": "3D subcortical atlases",
    "text": "3D subcortical atlases\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeaker notes go here.\n\n\nSitek and Gulban et al. (2019 eLife)"
  },
  {
    "objectID": "talk.html#in-vivo-functional-mri-mapping",
    "href": "talk.html#in-vivo-functional-mri-mapping",
    "title": "Imaging the neural systems underlying human communication",
    "section": "In vivo functional MRI mapping",
    "text": "In vivo functional MRI mapping\n\n\n7 Tesla functional MRI (1.1 mm voxels)\n\n168 natural sounds (1 s each): speech, voice, nature, tools, music, animals and monkey calls\nSound &gt; baseline contrast\n10 healthy participants\n2 hours per session\nCollected over 2 sessions\n\n\n\n\n\n\n\n\n\n\n\nParticipants listened to 168 natural sounds (1 s long) coming from seven categories (speech, voice, nature, tools, music, animals and monkey calls) presented in silent gaps in between the acquisition of functional volumes and were asked to press a button every time the same sound was repeated. The experimental paradigm followed a rapid-eventrelated design in which sounds were presented with a mean inter stimulus interval of four volumes (minimum three maximum five volumes). The two sessions were identical and each session consisted of twelve functional runs and across the 12 runs each sound was presented three times (i.e. each sounds was presented six times across the two sessions). The 168 sounds were divided in four sets of 42 sounds, each set was presented in three (non consecutive) runs. As a result, the 12 functional runs of each session formed four cross validation sets each one consisting of nine training runs and three testing runs (i.e. 126 training and 42 testing sounds). Note that the testing runs were non overlapping across the cross validations. Catch trials (i.e. sound repetitions) were added to each run, and were excluded from all analyses.\n\n\nSitek and Gulban et al. (2019 eLife)"
  },
  {
    "objectID": "talk.html#where-are-the-auditory-structures-three-public-atlases",
    "href": "talk.html#where-are-the-auditory-structures-three-public-atlases",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Where are the auditory structures: Three public atlases",
    "text": "Where are the auditory structures: Three public atlases\n\n\n\n\n\n\n\n\n\n\n\nSpeaker notes go here.\n\n\nSitek and Gulban et al. (2019 eLife)"
  },
  {
    "objectID": "talk.html#how-are-the-auditory-structures-connected-anatomically",
    "href": "talk.html#how-are-the-auditory-structures-connected-anatomically",
    "title": "Imaging the neural systems underlying human communication",
    "section": "How are the auditory structures connected anatomically?",
    "text": "How are the auditory structures connected anatomically?\n\n\nPost mortem\n\n\nIn vivo\n\n\n\n\n\n \n\n\nSitek and Gulban et al. (2019 eLife); Sitek et al. (2022 Frontiers Neuro)"
  },
  {
    "objectID": "talk.html#how-are-the-auditory-structures-connected-functionally",
    "href": "talk.html#how-are-the-auditory-structures-connected-functionally",
    "title": "Imaging the neural systems underlying human communication",
    "section": "How are the auditory structures connected functionally?",
    "text": "How are the auditory structures connected functionally?\nExtracting the pathway (partial correlations) from the network (simple correlations)\n\n\n\n\n\n\n7T Human Connectome Project (106 participants) resting state functional MRI\n\n\n\nSpeaker notes go here.\n\n\nChandra* and Sitek* et al. (2024 Imaging Neuro)"
  },
  {
    "objectID": "talk.html#how-are-the-auditory-structures-connected-functionally-1",
    "href": "talk.html#how-are-the-auditory-structures-connected-functionally-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "How are the auditory structures connected functionally?",
    "text": "How are the auditory structures connected functionally?\nExtracting the pathway (partial correlations) from the network (simple correlations)\n\n\n\n\n\n\n7T Human Connectome Project (106 participants) resting state functional MRI\n\n\n\nSpeaker notes go here.\n\n\nChandra* and Sitek* et al. (2024 Imaging Neuro)"
  },
  {
    "objectID": "talk.html#how-do-we-learn-new-sensory-categories",
    "href": "talk.html#how-do-we-learn-new-sensory-categories",
    "title": "Imaging the neural systems underlying human communication",
    "section": "How do we learn new sensory categories?",
    "text": "How do we learn new sensory categories?\n\n\n\n\nDorsal striatum contribute to learning new categories thanks to its many-to-one projections from distributed cortical networks that subserve:\n\nmotor planning\ntask-relevant sensory processing\nfeedback processing\ndecision-making\n\nDorsal striatum involved in auditory category learning tasks using fMRI (Feng et al., 2019; Lim et al., 2019; Yi et al., 2016)\n\nWhat anatomical pathways that connect the human auditory system to the striatum?\nHow do subdivisions of dorsal striatum functionally contribute to category learning?\n\n\n\n\n\n\n\nLim et al., 2014\n\n\n\n\n\n\n\nSpeaker notes go here.\n\n\nThis work is actively supported by K01-DC019421 (PI: Sitek)"
  },
  {
    "objectID": "talk.html#auditory-striatal-pathways-in-non-human-primates",
    "href": "talk.html#auditory-striatal-pathways-in-non-human-primates",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Auditory-striatal pathways in non-human primates",
    "text": "Auditory-striatal pathways in non-human primates\n\n\n\n\nMacaque (Yeterian & Pandya 1998)\n\n\n\n\n\nSpeaker notes go here."
  },
  {
    "objectID": "talk.html#auditory-striatal-pathways-in-the-human-brain",
    "href": "talk.html#auditory-striatal-pathways-in-the-human-brain",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Auditory-striatal pathways in the human brain",
    "text": "Auditory-striatal pathways in the human brain\n\n\n\n\nSitek et al. (in revision)\n\n\n\n\n\nSpeaker notes go here.\n\n\nHuman Connectome Project 7T diffusion-weighted MRI dataset (n = 100)"
  },
  {
    "objectID": "talk.html#similar-connectivity-patterns-in-humans-and-macaques",
    "href": "talk.html#similar-connectivity-patterns-in-humans-and-macaques",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Similar connectivity patterns in humans and macaques",
    "text": "Similar connectivity patterns in humans and macaques\n\n\n\n\n\n\n\nMacaque (Yeterian & Pandya 1998)\n\n\n\n\n\n\n\n\n\nHuman (Sitek et al. 2022 preprint, in revision)\n\n\n\n\n\n\n\n\nSpeaker notes go here."
  },
  {
    "objectID": "talk.html#how-do-humans-learn-new-sensory-categories",
    "href": "talk.html#how-do-humans-learn-new-sensory-categories",
    "title": "Imaging the neural systems underlying human communication",
    "section": "How do humans learn new sensory categories?",
    "text": "How do humans learn new sensory categories?\n\n\n\n\nAuditory category learning task with Mandarin tone stimuli1\n12 non-Mandarin-speaking participants (18–30 years old)\n7 Tesla high resolution functional MRI (1.5 mm isotropic vixels)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeaker notes go here.\n\n\n\nYi 2016; Reetzke 2018; Feng 2019; …"
  },
  {
    "objectID": "talk.html#successful-learning-of-new-auditory-categories-in-mri",
    "href": "talk.html#successful-learning-of-new-auditory-categories-in-mri",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Successful learning of new auditory categories in MRI",
    "text": "Successful learning of new auditory categories in MRI\n\n\n\nSpeaker notes go here.\n\n\nSitek et al. (in revision)"
  },
  {
    "objectID": "talk.html#successful-learning-of-new-auditory-categories-in-mri-1",
    "href": "talk.html#successful-learning-of-new-auditory-categories-in-mri-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Successful learning of new auditory categories in MRI",
    "text": "Successful learning of new auditory categories in MRI\n\n\n\nSpeaker notes go here.\n\n\nSitek et al. (in revision)"
  },
  {
    "objectID": "talk.html#successful-learning-of-new-auditory-categories-in-mri-2",
    "href": "talk.html#successful-learning-of-new-auditory-categories-in-mri-2",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Successful learning of new auditory categories in MRI",
    "text": "Successful learning of new auditory categories in MRI\n\n\n\nSpeaker notes go here.\n\n\nSitek et al. (in revision)"
  },
  {
    "objectID": "talk.html#auditory-fmri-responses-to-sound-presentation",
    "href": "talk.html#auditory-fmri-responses-to-sound-presentation",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Auditory fMRI responses to sound presentation",
    "text": "Auditory fMRI responses to sound presentation\n\n\n\nSound responses: everything significant except for ParsTri\n\n\nSitek et al. (in revision)"
  },
  {
    "objectID": "talk.html#fmri-responses-to-feedback-correct-vs.-wrong",
    "href": "talk.html#fmri-responses-to-feedback-correct-vs.-wrong",
    "title": "Imaging the neural systems underlying human communication",
    "section": "fMRI responses to feedback (“correct” vs. “wrong”)",
    "text": "fMRI responses to feedback (“correct” vs. “wrong”)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStriatum feedback responses\n\nAll regions showed positive responses in early learning stage\nBut only anterior putamen maintained positive responses across all runs\nOnly anterior caudate significantly decreased responses from early to final learning stages\n\n\n\n\n\nSound responses: everything significant except for ParsTri\nStronger responses overall in early vs. final learning stages (runs)\n\n\n\nSitek et al. (in revision)"
  },
  {
    "objectID": "talk.html#auditory-categorization-in-the-human-brain-1",
    "href": "talk.html#auditory-categorization-in-the-human-brain-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Auditory categorization in the human brain",
    "text": "Auditory categorization in the human brain\n\nWe identified putative cortico–striatal pathways for auditory decision-making\n\nPrimary/secondary auditory cortex connects more strongly with posterior dorsal striatum\nNon-invasive human connectivity is similar to invasive tracing in non-human primates (Yeterian & Pandya 1998)\n\n\n\nDynamics of learning and categorization in dorsal striatum\nWhen presented with feedback:\n\nAnterior caudate responds highest early on\nAnterior putamen responds across learning stages\n\n\nPutamen and caudate subdivisions have unique functional and connectivity profiles\n\n\nSpeaker notes go here.\n\n\nSitek et al. (in revision)"
  },
  {
    "objectID": "talk.html#human-speech-and-auditory-feedback-processing",
    "href": "talk.html#human-speech-and-auditory-feedback-processing",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Human speech and auditory feedback processing",
    "text": "Human speech and auditory feedback processing\n\n\nSuppressed cortical response to own voice while speaking (Houde & Jordan 2002)\n\n\n\n\n\n\nLess suppression when our own speech is variable (Sitek et al. 2013)\n\n\n\n\n\n\n\n\n\n\n\nThis work is actively supported by R21-DC022906 (PI: Sitek)."
  },
  {
    "objectID": "talk.html#studying-the-human-subcortical-auditory-system-with-eeg",
    "href": "talk.html#studying-the-human-subcortical-auditory-system-with-eeg",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Studying the human subcortical auditory system with EEG",
    "text": "Studying the human subcortical auditory system with EEG\nThe scalp-recorded frequency-following response (FFR) shows the fidelity of incoming sound encoding\n\n\n\n\n\n\n\n\n\n\nCoffey et al. (2018)"
  },
  {
    "objectID": "talk.html#where-are-motor-signals-integrated-subcortically",
    "href": "talk.html#where-are-motor-signals-integrated-subcortically",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Where are motor signals integrated? Subcortically?",
    "text": "Where are motor signals integrated? Subcortically?\n\n\n\n\n\nIf integration is subcortical:\n\nExpect to see FFR differences between self-generated and passive sound\n\nRecorded FFRs to /da/ stimulus\n\nActive condition: press a button to generate a sound\nPassive condion: passive presentation of the sound\n\nCollected data from 33 normal-hearing adults\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nButler, …, Sitek (in prep; SNL 2025)"
  },
  {
    "objectID": "talk.html#active-and-passive-evoked-responses",
    "href": "talk.html#active-and-passive-evoked-responses",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Active and passive evoked responses",
    "text": "Active and passive evoked responses\n\n\n\nBrainstem frequency-following response\n\n\nCortical evoked response\n\n\n\n\nFFR spectrograms don’t vary between conditions; neither do power or latency-to-first-peak\nAll of which do vary in cortical responses\n\n\nButler, …, Sitek (in prep; SNL 2025)"
  },
  {
    "objectID": "talk.html#where-are-motor-signals-integrated-subcortically-1",
    "href": "talk.html#where-are-motor-signals-integrated-subcortically-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Where are motor signals integrated? Subcortically?",
    "text": "Where are motor signals integrated? Subcortically?\n\nBrainstem frequency-following response (FFR) shows the same sound encoding when a sound is self-generated or passively presented\n\nNo brainstem FFR differences, despite cortical evoked response differences\nMotor signals unlikely to attenuate earliest central auditory signals\nNext steps:\n\nSource localization of FFR generators (ECR R21 project)\nCortical layer-specific feedback localization with 7T fMRI (planned R01)\n\n\n\n\nIf integration is subcortical, would expect to see FFR differences between self-generated vs. passive sound\n\n\nButler, …, Sitek (in prep; SNL 2025)"
  },
  {
    "objectID": "talk.html#future-research-directions",
    "href": "talk.html#future-research-directions",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Future research directions",
    "text": "Future research directions\n\n\n\n\n\n\nSensory and motor speech learning - Role of striatum across communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01\nHearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21\nTranslational insights - Adapting multi-echo fMRI to better understand hearing loss in middle age (Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep) - Auditory cortical mechanisms supporting compensation in children who stutter (Sitek et al., SNL 2025, in prep.) - Network connectivity supporting aphasia recovery\n\nME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke\nStuttering:\nCochlear implants:\nAphasia"
  },
  {
    "objectID": "talk.html#future-research-directions-1",
    "href": "talk.html#future-research-directions-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Future research directions",
    "text": "Future research directions\n\n\n\n\n\n\nSensory and motor speech learning - Role of striatum across communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01\nHearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21\nTranslational insights - Adapting multi-echo fMRI to better understand hearing loss in middle age (Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep) - Auditory cortical mechanisms supporting compensation in children who stutter (Sitek et al., SNL 2025, in prep.) - Network connectivity supporting aphasia recovery\n\nME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke\nStuttering:\nCochlear implants:\nAphasia"
  },
  {
    "objectID": "talk.html#future-research-directions-2",
    "href": "talk.html#future-research-directions-2",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Future research directions",
    "text": "Future research directions\n\n\n\n\n\n\nSensory and motor speech learning - Role of striatum across communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01\nHearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21\nTranslational insights - Adapting multi-echo fMRI to better understand hearing loss in middle age (Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep) - Auditory cortical mechanisms supporting compensation in children who stutter (Sitek et al., SNL 2025, in prep.) - Network connectivity supporting aphasia recovery\n\nME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke\nStuttering:\nCochlear implants:\nAphasia"
  },
  {
    "objectID": "talk.html#future-research-directions-3",
    "href": "talk.html#future-research-directions-3",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Future research directions",
    "text": "Future research directions\n\n\n\n\n\n\nSensory and motor speech learning - Role of striatum across communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01\nHearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21\nTranslational insights - Adapting multi-echo fMRI to better understand hearing loss in middle age (Medina, Sitek, et al., submitted; Medina, …, Sitek, in prep) - Auditory cortical mechanisms supporting compensation in children who stutter (Sitek et al., SNL 2025, in prep.) - Network connectivity supporting aphasia recovery\n\nME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke\nStuttering:\nCochlear implants:\nAphasia"
  },
  {
    "objectID": "talk.html#sensory-and-motor-speech-learning-shared-striatal-mechanisms",
    "href": "talk.html#sensory-and-motor-speech-learning-shared-striatal-mechanisms",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Sensory and motor speech learning: Shared striatal mechanisms?",
    "text": "Sensory and motor speech learning: Shared striatal mechanisms?\n\n\n\nDorsal striatum (caudate and putamen) is critical to auditory learning (Sitek et al., in revision) and motor learning\nAre the neural implementations shared across perceptual and motor learning in the context of speech and language?\nHow are shared mechanisms affected in stuttering or Parkinson’s, and can they inform therapeutic opportunities?\n\n\n\n\n\nLim et al., 2014\n\n\n\n\nStuttering Treatment implications Learning-based therapy, not just fluency shaping Emphasize rewarded, gradually stabilized speech patterns Closed-loop auditory reinforcement paradigms More targeted dopamine modulation (dose, timing, task-coupled) Neurostimulation aimed at striatal–SMA loops, not just cortex\nDyslexia Treatment implications Shift from pure phonics to reinforcement-based learning frameworks Use adaptive reward schedules to strengthen sound–action associations Predict differential benefit from procedural vs declarative training Early identification via auditory category learning tasks, not just phonological tests\nParkinson’s Treatment implications Therapy timed to dopaminergic state to optimize learning Use of external reinforcement and cueing to replace striatal learning Personalized speech therapy based on learning rate, not just severity Speech as a biomarker for basal ganglia learning capacity"
  },
  {
    "objectID": "talk.html#hearing-our-own-speech-where-are-motor-signals-integrated-in-auditory-cortex",
    "href": "talk.html#hearing-our-own-speech-where-are-motor-signals-integrated-in-auditory-cortex",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Hearing our own speech: Where are motor signals integrated in auditory cortex?",
    "text": "Hearing our own speech: Where are motor signals integrated in auditory cortex?\n\n\n\nAuditory cortex is a hub for motor integration\nBut fMRI often shows increased BOLD to self-generated sounds, vs. suppressed M/EEG\nAre different laminar responses the explanation?\n\nWe can look at intra-cortical circuits with ultra-high field 7T fMRI\n\n\n\n\nBehroozmand et al. (2015)\n\n\n\n\n\nReznik et al. (2015)\n\n\n\n\n\nBehroozmand (2015) discussion para 2: &gt; When compared to rest, we found that during both speaking and playback conditions, the strongest activation in response to normal (no shift) and pitch-shifted vowel sound was observed within temporal lobe auditory cortices. This temporal lobe activation did not differ significantly for the speaking versus playback conditions. However, during speaking, we found significant BOLD activation increases in other sensory–motor areas including bilateral precentral gyrus, postcentral gyrus, anterior insula, SMA and IFG compared with playback. The speaking-induced BOLD response enhancement in these sensory–motor areas was not significantly modulated by the presence or absence of pitch-shift stimulus in the auditory feedback."
  },
  {
    "objectID": "talk.html#hearing-our-own-speech-where-are-motor-signals-integrated-in-auditory-cortex-1",
    "href": "talk.html#hearing-our-own-speech-where-are-motor-signals-integrated-in-auditory-cortex-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Hearing our own speech: Where are motor signals integrated in auditory cortex?",
    "text": "Hearing our own speech: Where are motor signals integrated in auditory cortex?\n\n\n\nAuditory cortex is a hub for motor integration\nBut fMRI has shown increased BOLD to self-generated sounds, vs. suppressed M/EEG\nAre different laminar responses the explanation?\n\nWe can look at intra-cortical circuits with ultra-high field 7T fMRI\n\nCortical depth profile differences during self-generated vs. passive sound listening\nHigher increases at superficial cortical depths, suggesting increased corticocortical feedback\nFuture work: Pinpointing feedback dysfunction in stuttering, schizophrenia, and other feedback processing disorders\n\n\n\n\n\nBehroozmand et al. (2015)\n\n\n\n\n\nReznik et al. (2015)\n\n\n\n\n\nSitek et al. (OHBM 2025)\n\n\n\n\n\n\nReproducible—same cortical depth effects in two acquisitions in the same participant"
  },
  {
    "objectID": "talk.html#improving-clinical-translation-at-3t-with-multi-echo-fmri",
    "href": "talk.html#improving-clinical-translation-at-3t-with-multi-echo-fmri",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Improving clinical translation at 3T with multi-echo fMRI",
    "text": "Improving clinical translation at 3T with multi-echo fMRI\n\n\n\n\nMulti-echo fMRI improves subcortical (and cortical!) fMRI sensitivity\n\nTypical fMRI uses one readout (“echo”)\nBut optimal echo time (TE) isn’t consistent across the brain\nMulti-echo fMRI allows optimal combination of different TEs across the brain\n\n\n\nListening task in 3T fMRI\n\n14 participants\n10 minutes of pop-song listening\n3 participants returned for precision-mapping session\nMulti-echo fMRI acquisition from UMinn CMRR\n\n\n\n\n\n\nDartmouth BIC\n\n\n\n\n\nSo far, each of the results I’ve shown have used 7 Tesla MRI. These are becoming more prevalent, especially now that the Siemens Terra is approved by the FDA. But they’re still much less common than 3 Tesla MRIs. Fortunately, data acquisition protocols have improved sensitivty even at 3T, so that we can reliably identify auditory midbrain and thalamus.\n\nMulti-echo fMRI acquisition\n\nEcho times = 13.40/39.5/65.6 ms\nRepetition time = 2.2 s\nMultiband factor = 2\nVoxel size = 1.731×1.731×4 mm3\nWhole-brain coverage (44 slices, FOV=180mm)\n\nMulti-echo optimal combination + ICA noise removal (tedana)\n\n\n\nMedina et al. (submitted preprint); Medina, …, Sitek (in prep.)"
  },
  {
    "objectID": "talk.html#improved-precision-mapping-with-multi-echo-fmri",
    "href": "talk.html#improved-precision-mapping-with-multi-echo-fmri",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Improved precision mapping with multi-echo fMRI",
    "text": "Improved precision mapping with multi-echo fMRI\n\n\n\nMulti-echo requires less scan time to identify auditory brainstem\n\n\n\n\n\n\nSubcortical activations are stronger with multi-echo than single-echo fMRI\n\n\n\n\n\n\n\n\n\n\n\nMedina et al. (submitted preprint); Medina, …, Sitek (in prep.)"
  },
  {
    "objectID": "talk.html#improving-brainstem-sensitivity-at-3t-with-multi-echo-fmri-1",
    "href": "talk.html#improving-brainstem-sensitivity-at-3t-with-multi-echo-fmri-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Improving brainstem sensitivity at 3T with multi-echo fMRI",
    "text": "Improving brainstem sensitivity at 3T with multi-echo fMRI\nFuture applications: Auditory processing across the lifespan\n\n\nAuditory processing changes throughout adulthood\n\nHow does speech-in-noise processing change in middle age and beyond?\nWhat neural patterns predict later cochlear implant success?\n\n\nSpeech processing in the developing brain\n\nHow do children make auditory category decisions, and how are they affected by noise?\nWhat compensatory neural pathways are available to children with developmental communication differences?\n\n\n\n\n\n\nMoser et al. (2025)\n\n\n\n\nMoser et al. (2025): https://doi.org/10.1162/imag_a_00426 “The sample consists of one adult (PA001) and two children (PC001 and PC002; age 10) enrolled at the University of Minnesota (UMN), and one adult (PA002) and three healthy neonates enrolled at Washington University in St. Louis (WashU), ages 28 days (43 weeks postmenstrual age (wPMA); PB004), 12 days (41 wPMA; PB005), and 13 days (41 wPMA; PB001)”"
  },
  {
    "objectID": "talk.html#a-systems-level-approach-to-human-speech-neuroscience-3",
    "href": "talk.html#a-systems-level-approach-to-human-speech-neuroscience-3",
    "title": "Imaging the neural systems underlying human communication",
    "section": "A systems-level approach to human speech neuroscience",
    "text": "A systems-level approach to human speech neuroscience"
  },
  {
    "objectID": "talk.html#acknowledgments",
    "href": "talk.html#acknowledgments",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\n\nSoundBrain Lab\n\nBharath Chandrasekaran, Jacie McHaney, Kailyn McFarlane\nNike Gnanateja (now UW Madison CSD)\nCasey Roark (now U New Hampshire Psychology)\n\n\n\nNorthwestern: Molly Bright, Michelle Medina (BME PhD student), Gabby Butler (Cog Sci UG honors student), Max Chen (Cog Sci/Comp Sci undergrad)\nUT Austin collaborators: Abhra Sarkar, Noirrit Chandra (UT Dallas), Blake Moya (industry)\nPitt: Jay Bohland, Mandy Hampton Wray\nHarvard/MIT: Satra Ghosh (PhD advisor)\nActive funding and support\n\nK01 DC019421 (2023–2027)\nR21 DC022906 (2025–2028)\nR01 DC020963 (2024–2027; PI: Bohland)\n\n\n\nSpeaker notes go here."
  },
  {
    "objectID": "talk.html#how-is-the-brainstem-supplied-oxygen",
    "href": "talk.html#how-is-the-brainstem-supplied-oxygen",
    "title": "Imaging the neural systems underlying human communication",
    "section": "How is the brainstem supplied oxygen?",
    "text": "How is the brainstem supplied oxygen?\n\n\n\n\n\n\n\nVessel ink staining (Duvernoy 1978)\n\n\n\n\n\n\n\nT2*-w MRI max. intensity projection\n\n\n\n\n\n\n\n\n\n\n\nVideo: 1920x1088\n\n\nXu et al. (ISMRM 2025); Xu, …, S. Bollmann, Sitek (in prep.)"
  },
  {
    "objectID": "talk.html#how-is-the-brainstem-supplied-oxygen-1",
    "href": "talk.html#how-is-the-brainstem-supplied-oxygen-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "How is the brainstem supplied oxygen?",
    "text": "How is the brainstem supplied oxygen?"
  },
  {
    "objectID": "talk.html#finger-motor-representation-in-the-human-brain",
    "href": "talk.html#finger-motor-representation-in-the-human-brain",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Finger motor representation in the human brain",
    "text": "Finger motor representation in the human brain\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosterior mean dominance greater than 25% across voxels for the right index (red), left index (blue), and middle fingers (green).\n\n\n\nMoya et al. Results for the fingertip mapping study:\nFingertip dominance across the investigated regions. Posterior mean dominance greater than \\(25\\%\\) is shown across voxels for the right index finger (red), left index (blue), and middle fingers (green) based on the estimated partition structures and the estimated effect intensities.\nColors blend when two or more fingers exhibit greater than \\(25\\%\\) dominance probabilities at the same location, showing areas of competing dominance for the right index and either middle finger (yellow), left index and either middle finger (cyan), and the two index fingers (purple).\n\n\nMoya et al. (in prep.)"
  },
  {
    "objectID": "talk.html#the-developing-auditory-system",
    "href": "talk.html#the-developing-auditory-system",
    "title": "Imaging the neural systems underlying human communication",
    "section": "The developing auditory system",
    "text": "The developing auditory system\nHow do we learn to hear in noisy environments?\n\n\n\n\nAdults: maturation of speech network1 + compensatory networks2\nChildren: fine-tuning speech network + undeveloped frontal networks\nCollected syllable-in-noise task fMRI at 3T in 35 typically developing kids\n\n5 speech-shaped noise contexts: Quiet and SNR = +8, 0, -2, and -6\nTask: identify which of 4 syllables were presented\n\n\n\n\n\n\n\nvia The Telegraph\n\n\n\n\n\n\n\nSSP\n\n\nSitek et al. (in prep.; SNL 2025)\nDu et al. (2014)Vaden et al. (2013); Eckert et al. (2016)"
  },
  {
    "objectID": "talk.html#the-developing-auditory-system-speech-in-quiet-vs.-baseline-fmri-contrast",
    "href": "talk.html#the-developing-auditory-system-speech-in-quiet-vs.-baseline-fmri-contrast",
    "title": "Imaging the neural systems underlying human communication",
    "section": "The developing auditory system: Speech-in-quiet vs. baseline fMRI contrast",
    "text": "The developing auditory system: Speech-in-quiet vs. baseline fMRI contrast\n\n\n\n\n\n\n\nSSP\n\n\nSitek et al. (in prep.; SNL 2025)"
  },
  {
    "objectID": "talk.html#the-developing-auditory-system-speech-in-quiet-vs.--6-db-snr",
    "href": "talk.html#the-developing-auditory-system-speech-in-quiet-vs.--6-db-snr",
    "title": "Imaging the neural systems underlying human communication",
    "section": "The developing auditory system: Speech-in-quiet vs. -6 dB SNR",
    "text": "The developing auditory system: Speech-in-quiet vs. -6 dB SNR\n\n\n\n\n\n\n\nSSP\n\n\nSitek et al. (in prep.; SNL 2025)"
  },
  {
    "objectID": "talk.html#systems-for-speech-in-noise-processing-are-actively-developing-in-adolescents",
    "href": "talk.html#systems-for-speech-in-noise-processing-are-actively-developing-in-adolescents",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Systems for speech-in-noise processing are actively developing in adolescents",
    "text": "Systems for speech-in-noise processing are actively developing in adolescents\n\n\n\n\nChildren activate broad canonical auditory and language regions more strongly in clear speech compared to noisy stimuli\nNo evidence that they utilize compensatory motor and prefrontal regions seen in adults\nInvestigating task-relevant representations in development\nCurrently collecting data in children who stutter\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSP\n\n\nSitek et al. (in prep.; SNL 2025);\nHampton-Wray R01DC019904"
  },
  {
    "objectID": "talk.html#multi-echo-fmri-improves-group-level-sensitivity-at-3t-1",
    "href": "talk.html#multi-echo-fmri-improves-group-level-sensitivity-at-3t-1",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Multi-echo fMRI improves group-level sensitivity at 3T",
    "text": "Multi-echo fMRI improves group-level sensitivity at 3T\n\n\n\n\n\n\n\n\n\n\n\nSpeaker notes go here.\n\n\nMedina et al. (submitted preprint); Medina, …, Sitek (in prep.)"
  },
  {
    "objectID": "talk.html#greater-self-generated-vs.-passive-fmri-responses-in-a-single-participant-across-replications",
    "href": "talk.html#greater-self-generated-vs.-passive-fmri-responses-in-a-single-participant-across-replications",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Greater self-generated vs. passive fMRI responses in a single participant across replications",
    "text": "Greater self-generated vs. passive fMRI responses in a single participant across replications\n\n\n\n\n\n\n\n\nSpeaker notes go here.\n\n\nSitek et al. (OHBM 2025)"
  },
  {
    "objectID": "talk.html#stronger-self-generated-vs.-passive-sound-responses-in-superficial-auditory-cortex",
    "href": "talk.html#stronger-self-generated-vs.-passive-sound-responses-in-superficial-auditory-cortex",
    "title": "Imaging the neural systems underlying human communication",
    "section": "Stronger self-generated (vs. passive) sound responses in superficial auditory cortex",
    "text": "Stronger self-generated (vs. passive) sound responses in superficial auditory cortex\n\n\n\nSpeaker notes go here.\n\n\n\n\nSitek et al. (OHBM 2025)"
  }
]