<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-cd7454b418030687c631a6a7286fbe16.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.22">

  <meta name="author" content="Kevin R. Sitek, Ph.D.">
  <meta name="dcterms.date" content="2025-01-22">
  <title>Imaging the neural systems underlying human communication</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-2a0bfdc6ab270f2428998c2b201918ac.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="./images/KevinSitek_postmortem-human-brainstem_auditory-tractography.png" data-background-opacity="0.25" data-background-size="contain" class="quarto-title-block center">
  <h1 class="title">Imaging the neural systems underlying human communication</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Kevin R. Sitek, Ph.D. 
</div>
        <p class="quarto-title-affiliation">
            Northwestern University Communication Sciences and Disorders
          </p>
    </div>
</div>

  <p class="date">2025-01-22</p>
</section>
<section id="a-systems-level-approach-to-human-speech-neuroscience" class="slide level2 unlisted" data-visibility="uncounted">
<h2>A systems-level approach to human speech neuroscience</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_overview/Slide1.png" class="fragment quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
</section>
<section id="a-systems-level-approach-to-human-speech-neuroscience-1" class="slide level2 unlisted" data-visibility="uncounted">
<h2>A systems-level approach to human speech neuroscience</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_overview/Slide2.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
<aside class="notes">
<p>Sensory behavior - how we use auditory information to learn about and act in the world</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="a-systems-level-approach-to-human-speech-neuroscience-2" class="slide level2 unlisted" data-visibility="uncounted">
<h2>A systems-level approach to human speech neuroscience</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_overview/Slide3.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
<aside class="notes">
<p>Identifying brain structure and function in <em>atypical communication</em>, and learning new questions to ask neuroscience</p>
<p>(not necessarily to diagnose, but rather to identify neural characteristics associated with a disorder, and perhaps to optimize treatment)</p>
<p>Established collaborations: - Functional and structural connectivity in <strong>persistent developmental stuttering</strong> (Sitek et al., 2016; ongoing Pitt collaboration) - Speech feedback control in individuals with <strong>cerebellar stroke</strong> (R01 Co-Investigator; PI: Bohland) - White matter pathways in <strong>autism spectrum disorder</strong> (Boets et al., 2018) - White matter integrity in <strong>sensorineural hearing loss</strong> (Tarabichi et al., 2018)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section>
<section id="my-path-to-speech-hearing-and-the-brain" class="title-slide slide level1 center">
<h1>My path to speech, hearing, and the brain</h1>

</section>
<section id="first-steps-linguistics-and-cognitive-science-undergraduate-at-uc-berkeley" class="slide level2" data-visibility="uncounted">
<h2>First steps: Linguistics and Cognitive Science Undergraduate at UC Berkeley</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_academic-bio/Slide2.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>

<aside><div>
<p>Sitek &amp; Johnson (2012 Chicago Linguistic Society). “Ipsilateral and contralateral phonetic context effects”.</p>
</div></aside></section>
<section id="brain-imaging-research-assistant-at-ucsfsan-francisco-va-medical-center" class="slide level2" data-visibility="uncounted">
<h2>Brain imaging research assistant at UCSF/San Francisco VA Medical Center</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_academic-bio/Slide3.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>

<aside><div>
<p>Sitek et al.&nbsp;(2013). “Auditory cortex processes variation in our own speech”.</p>
</div></aside></section>
<section id="phd-in-speech-and-hearing-bioscience-and-technology-at-harvardmit" class="slide level2" data-visibility="uncounted">
<h2>PhD in Speech and Hearing Bioscience and Technology at Harvard/MIT</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_academic-bio/Slide4.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>

<aside><div>
<p><strong>NRSA F31</strong> (2016–2018); Sitek et al.&nbsp;(2016), Connectivity and <strong>stuttering</strong> severity; Sitek and Gulban et al.&nbsp;(2019), “Mapping the human <strong>subcortical auditory system</strong>”.</p>
</div></aside></section>
<section id="postdoctoral-research-in-neuroscience-at-baylor-college-of-medicine" class="slide level2" data-visibility="uncounted">
<h2>Postdoctoral research in Neuroscience at Baylor College of Medicine</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_academic-bio/Slide5.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>

<aside><div>
<p>Ultra-high field 9.4 Tesla functional MRI of the human midbrain (collaborative CRCNS with Tübingen)</p>
</div></aside></section>
<section id="research-scientist-in-communication-science-and-disorders-at-the-university-of-pittsburgh" class="slide level2" data-visibility="uncounted">
<h2>Research Scientist in Communication Science and Disorders at the University of Pittsburgh</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_academic-bio/Slide6.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>

<aside><div>
<p><strong>NIH K01</strong> (2022–2027); Sitek et al.&nbsp;(2022), Structural connectivity of human inferior colliculus</p>
</div></aside></section>
<section id="now-research-assistant-professor-at-northwestern-university" class="slide level2" data-visibility="uncounted">
<h2>Now: Research Assistant Professor at Northwestern University</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_academic-bio/Slide7.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>

<aside><div>
<p><strong>NIH R21</strong> (2025–2028); auditory learning and auditory–motor interactions</p>
</div></aside></section>
<section id="widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship" class="slide level2">
<h2>Widening perspectives and expanding opportunities through teaching and mentorship</h2>
</section>
<section id="widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-1" class="slide level2" data-visibility="uncounted">
<h2>Widening perspectives and expanding opportunities through teaching and mentorship</h2>

<img data-src="images/Sitek_teaching/Slide1.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<ul>
<li>Speech Production (MIT/Harvard Teaching Assistant)
<ul>
<li>Lecture on articulatory phonetics</li>
<li>Bok Teaching Center Award for Teaching Excellence</li>
</ul></li>
<li>The human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)</li>
<li>Subcortical contributions to language (UT Dallas guest lecture)</li>
<li>Communicating Science (Northwestern CSD PhD program)
<ul>
<li>Tailoring your written/oral/visual presentations to your specific audience</li>
<li>Builds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)</li>
<li>73% of students rated the course at the highest possible level</li>
</ul></li>
<li>Northwestern PhD committee/co-mentorship
<ul>
<li>Serena Mon (CSD)</li>
<li>Michelle Medina (BME; Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>)</li>
</ul></li>
<li>Northwestern undergraduate mentorship
<ul>
<li>Gabby Butler (Cognitive Science; Butler, …, Sitek, <em>in prep</em>)</li>
<li>Max Chen (Cognitive Science/Computer Science)</li>
</ul></li>
<li>Pitt AuD/undergraduate co-mentorship</li>
</ul>
<p>As well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-2" class="slide level2" data-visibility="uncounted">
<h2>Widening perspectives and expanding opportunities through teaching and mentorship</h2>

<img data-src="images/Sitek_teaching/Slide2.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<ul>
<li>Speech Production (MIT/Harvard Teaching Assistant)
<ul>
<li>Lecture on articulatory phonetics</li>
<li>Bok Teaching Center Award for Teaching Excellence</li>
</ul></li>
<li>The human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)</li>
<li>Subcortical contributions to language (UT Dallas guest lecture)</li>
<li>Communicating Science (Northwestern CSD PhD program)
<ul>
<li>Tailoring your written/oral/visual presentations to your specific audience</li>
<li>Builds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)</li>
<li>73% of students rated the course at the highest possible level</li>
</ul></li>
<li>Northwestern PhD committee/co-mentorship
<ul>
<li>Serena Mon (CSD)</li>
<li>Michelle Medina (BME; Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>)</li>
</ul></li>
<li>Northwestern undergraduate mentorship
<ul>
<li>Gabby Butler (Cognitive Science; Butler, …, Sitek, <em>in prep</em>)</li>
<li>Max Chen (Cognitive Science/Computer Science)</li>
</ul></li>
<li>Pitt AuD/undergraduate co-mentorship</li>
</ul>
<p>As well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-3" class="slide level2" data-visibility="uncounted">
<h2>Widening perspectives and expanding opportunities through teaching and mentorship</h2>

<img data-src="images/Sitek_teaching/Slide3.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<ul>
<li>Speech Production (MIT/Harvard Teaching Assistant)
<ul>
<li>Lecture on articulatory phonetics</li>
<li>Bok Teaching Center Award for Teaching Excellence</li>
</ul></li>
<li>The human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)</li>
<li>Subcortical contributions to language (UT Dallas guest lecture)</li>
<li>Communicating Science (Northwestern CSD PhD program)
<ul>
<li>Tailoring your written/oral/visual presentations to your specific audience</li>
<li>Builds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)</li>
<li>73% of students rated the course at the highest possible level</li>
</ul></li>
<li>Northwestern PhD committee/co-mentorship
<ul>
<li>Serena Mon (CSD)</li>
<li>Michelle Medina (BME; Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>)</li>
</ul></li>
<li>Northwestern undergraduate mentorship
<ul>
<li>Gabby Butler (Cognitive Science; Butler, …, Sitek, <em>in prep</em>)</li>
<li>Max Chen (Cognitive Science/Computer Science)</li>
</ul></li>
<li>Pitt AuD/undergraduate co-mentorship</li>
</ul>
<p>As well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="widening-perspectives-and-expanding-opportunities-through-teaching-and-mentorship-4" class="slide level2" data-visibility="uncounted">
<h2>Widening perspectives and expanding opportunities through teaching and mentorship</h2>

<img data-src="images/Sitek_teaching/Slide4.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<ul>
<li>Speech Production (MIT/Harvard Teaching Assistant)
<ul>
<li>Lecture on articulatory phonetics</li>
<li>Bok Teaching Center Award for Teaching Excellence</li>
</ul></li>
<li>The human subcortical auditory system (Pitt AuD program; Pitt CSD undergrad program guest lectures)</li>
<li>Subcortical contributions to language (UT Dallas guest lecture)</li>
<li>Communicating Science (Northwestern CSD PhD program)
<ul>
<li>Tailoring your written/oral/visual presentations to your specific audience</li>
<li>Builds on my own work expanding access to high quality science (Wearn, Sitek, et al., 2025; Sitek et al., 2025)</li>
<li>73% of students rated the course at the highest possible level</li>
</ul></li>
<li>Northwestern PhD committee/co-mentorship
<ul>
<li>Serena Mon (CSD)</li>
<li>Michelle Medina (BME; Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>)</li>
</ul></li>
<li>Northwestern undergraduate mentorship
<ul>
<li>Gabby Butler (Cognitive Science; Butler, …, Sitek, <em>in prep</em>)</li>
<li>Max Chen (Cognitive Science/Computer Science)</li>
</ul></li>
<li>Pitt AuD/undergraduate co-mentorship</li>
</ul>
<p>As well as informal PhD/PD mentorship as faculty in the SoundBrain Lab, including writing group leadership and technical mentorship</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="research-contributions-to-communication-neuroscience" class="slide level2">
<h2>Research contributions to communication neuroscience</h2>
<div class="columns">
<div class="column fragment">
<h3 id="mapping-the-human-subcortical-auditory-system">Mapping the human subcortical auditory system</h3>
<ul>
<li><strong>Anatomy</strong> (Sitek &amp; Gulban et al., 2019)</li>
<li><strong>Function</strong> (Sitek &amp; Gulban et al., 2019; Medina, Sitek, et al., submitted preprint)</li>
<li><strong>Structural and functional connectivity</strong> (Sitek &amp; Gulban et al., 2019; Sitek et al., 2022; Chandra &amp; Sitek et al., 2024)</li>
<li><strong>Neurovascular organization</strong> (Xu et al., ISMRM 2025; Xu, …, S. Bollmann<em>, Sitek</em>, in prep.)</li>
</ul>
</div><div class="column fragment">
<h3 id="behavior-of-the-human-auditory-system">Behavior of the human auditory system</h3>
<ul>
<li><strong>Auditory categorization</strong> in the human brain (Sitek et al., in re-review; Llanos &amp; Sitek et al., in re-review; Deschamps, Sitek, et al., in prep.)</li>
<li><strong>Auditory–motor interactions</strong> across the auditory pathway (Butler, …, Sitek, in prep.)</li>
<li><strong>Top–down modulation of predicted sound processing</strong> across the auditory pathway (Ara et al., 2024)</li>
<li><strong>Speech-in-noise processing</strong> in the developing brain (Sitek et al., SNL 2025; in prep.)</li>
</ul>
</div></div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>This work is actively supported by K01-DC019421 and R21-DC022906 and was previously supported by F31-DC015695.</p>
</div></aside></section></section>
<section>
<section id="research-contributions-auditory-circuits-throughout-the-human-brain" class="title-slide slide level1 center">
<h1>Research contributions: Auditory circuits throughout the human brain</h1>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="whats-special-about-the-auditory-system" class="slide level2">
<h2>What’s special about the auditory system?</h2>
<div class="quarto-layout-panel" data-layout="[60,40]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/schematic-auditorysystem.png" height="800"></p>
<figcaption>Kaas &amp; Hackett (2000)</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/schematic-visualsystem.png" height="800"></p>
<figcaption>Van Essen et al.&nbsp;(1992)</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="whats-special-about-the-auditory-system-1" class="slide level2" data-visibility="uncounted">
<h2>What’s special about the auditory system?</h2>
<div class="quarto-layout-panel" data-layout="[60,40]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/schematic-auditorysystem_box-subcort.png" height="800"></p>
<figcaption>Kaas &amp; Hackett (2000)</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/schematic-visualsystem_box-subcort.png" height="800"></p>
<figcaption>Van Essen et al.&nbsp;(1992)</figcaption>
</figure>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>So why should we focus on the subcortical parts of the auditory system? I said that those are the harder parts to investigate with MRI, right? Well, there’s actually a lot going on in the brainstem and thalamus, especially in the auditory system. Two examples from primates show differences between the wiring of the auditory and visual systems. In the auditory system, the first 5 layers of the system are subcortical, and with some cross-talk between them, so some processing can pass through even more structures. Meanwhile, in the visual system, there’s just one or two stages before hitting primary sensory cortex. Indeed, a lot of processing is already done by the retina itself. With other features extracted later in successively higher levels of visual cortex. Whereas in the auditory system, there’s some basic frequency and sound level information pulled out by the cochlea, but some other features like location of sound sources are extracted in the brainstem.</p>
<p>BUT THE VAST MAJORITY OF OUR KNOWLEDGE COMES FROM ANIMAL STUDIES</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-human-subcortical-auditory-system" class="slide level2">
<h2>The human subcortical auditory system</h2>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Rotation_brainstem_and_thalamus.gif" class="fragment quarto-figure quarto-figure-center" height="800"></p>
</figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Auditory_Pathway.png" class="fragment quarto-figure quarto-figure-center" height="800"></p>
</figure>
</div>
</div></div>
<div class="fragment">
<h3 id="but-small-deep-brain-structures-are-challenging-to-image.">But: small, deep brain structures are challenging to image.</h3>
</div>
<aside class="notes">
<p>Across human behaviors, studying the brainstem is challenging. - In vivo MRI limited by: - high resolution needed for small structures - decreased signal as voxels get smaller - decreased signal in brainstem - Limited spatial information from EEG, MEG - Some human histology studies (nuclei) - Tracer studies (connections) only in animal models</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section>
<section id="mapping-the-human-subcortical-auditory-system-1" class="title-slide slide level1 center">
<h1>Mapping the human subcortical auditory system</h1>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>


<section id="post-mortem-anatomical-localization" class="slide level2">
<h2>Post mortem anatomical localization</h2>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img data-src="images/SitekGulban2019_postmortem-1_labeled.png" class="fragment"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img data-src="images/SitekGulban2019_postmortem-2_labeled.png" class="fragment"></p>
</div>
</div>
</div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek and Gulban et al.&nbsp;(2019 <em>eLife</em>)</p>
</div></aside></section>
<section id="d-subcortical-atlases" class="slide level2">
<h2>3D subcortical atlases</h2>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img data-src="images/SitekGulban2019/fig_literature_and_bigbrain.png" class="fragment"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img data-src="images/SitekGulban2019/fig_exvivo_atlas_3D_atlas.png" class="fragment"></p>
</div>
</div>
</div>
<p><img data-src="images/people/Omer-Faruk-Gulban.jpg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek and Gulban et al.&nbsp;(2019 <em>eLife</em>)</p>
</div></aside></section>
<section id="in-vivo-functional-mri-mapping" class="slide level2">
<h2>In vivo functional MRI mapping</h2>
<div class="columns">
<div class="column fragment" style="width:27%;">
<h3 id="tesla-functional-mri-1.1-mm-voxels">7 Tesla functional MRI (1.1 mm voxels)</h3>
<ul>
<li>168 natural sounds (1 s each): speech, voice, nature, tools, music, animals and monkey calls</li>
<li>Sound &gt; baseline contrast</li>
<li>10 healthy participants</li>
<li>2 hours per session</li>
<li>Collected over 2 sessions</li>
</ul>
</div><div class="column fragment" style="width:73%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/SitekGulban2019/fig_invivo_statmaps_and_exvivo_vasculature.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
</div></div>
<p><img data-src="images/people/Omer-Faruk-Gulban.jpg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p>Participants listened to 168 natural sounds (1 s long) coming from seven categories (speech, voice, nature, tools, music, animals and monkey calls) presented in silent gaps in between the acquisition of functional volumes and were asked to press a button every time the same sound was repeated. The experimental paradigm followed a rapid-eventrelated design in which sounds were presented with a mean inter stimulus interval of four volumes (minimum three maximum five volumes). The two sessions were identical and each session consisted of twelve functional runs and across the 12 runs each sound was presented three times (i.e.&nbsp;each sounds was presented six times across the two sessions). The 168 sounds were divided in four sets of 42 sounds, each set was presented in three (non consecutive) runs. As a result, the 12 functional runs of each session formed four cross validation sets each one consisting of nine training runs and three testing runs (i.e.&nbsp;126 training and 42 testing sounds). Note that the testing runs were non overlapping across the cross validations. Catch trials (i.e.&nbsp;sound repetitions) were added to each run, and were excluded from all analyses.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek and Gulban et al.&nbsp;(2019 <em>eLife</em>)</p>
</div></aside></section>
<section id="where-are-the-auditory-structures-three-public-atlases" class="slide level2">
<h2><em>Where</em> are the auditory structures: Three public atlases</h2>
<div class="r-stack">
<video id="video_shortcode_videojs_video1" width="1278" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="images/SitekGulban2019/elife-48932-fig9-video1.mp4"></video>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/SitekGulban2019/fig_MNI-videos_bigbrain_postmortem_invivo_statmap_invivo_overlap.png" class="fragment quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<p><img data-src="images/people/Omer-Faruk-Gulban.jpg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek and Gulban et al.&nbsp;(2019 <em>eLife</em>)</p>
</div></aside></section></section>
<section>
<section id="connectivity-of-the-human-subcortical-auditory-system" class="title-slide slide level1 center">
<h1>Connectivity of the human subcortical auditory system</h1>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="how-are-the-auditory-structures-connected-anatomically" class="slide level2">
<h2>How are the auditory structures connected <strong>anatomically</strong>?</h2>
<div class="{columns}">
<div class="column fragment">
<h4 id="post-mortem">Post mortem</h4>
<video id="video_shortcode_videojs_video2" width="922" height="720" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="images/SitekGulban2019/elife-48932-fig3-video1.mp4"></video>
</div><div class="column fragment">
<h4 id="in-vivo">In vivo</h4>
<video id="video_shortcode_videojs_video3" width="922" height="720" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="images/SitekGulban2019/elife-48932-fig6-video1.mp4"></video>
</div></div>
<p><img data-src="images/people/Omer-Faruk-Gulban.jpg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p><img data-src="images/SitekGulban2019/fig_postmortem_streamlines_kevin_v2_faruk_v1_May31.png" class="quarto-figure quarto-figure-center" height="777" alt="Post mortem"> <img data-src="images/SitekGulban2019/fig_invivo_diffusion_schematic_heatmap+schematic_16May.png" class="fragment quarto-figure quarto-figure-center" height="777" alt="In vivo"></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek and Gulban et al.&nbsp;(2019 <em>eLife</em>); Sitek et al.&nbsp;(2022 <em>Frontiers Neuro</em>)</p>
</div></aside></section>
<section id="how-are-the-auditory-structures-connected-functionally" class="slide level2 smaller">
<h2>How are the auditory structures connected <strong>functionally</strong>?</h2>
<h4 class="fragment" id="extracting-the-pathway-partial-correlations-from-the-network-simple-correlations">Extracting the <em>pathway</em> (partial correlations) from the <em>network</em> (simple correlations)</h4>
<div class="{columns}">
<div class="column" style="width:30%;">
<p><img data-src="images/ChandraSitek/FAC_fig-2_regions.png" class="fragment"></p>
</div><div class="column" style="width:70%;">
<p><img data-src="images/ChandraSitek/composite_Slide1.png" class="fragment"></p>
</div></div>
<p>7T Human Connectome Project (106 participants) resting state <strong>functional</strong> MRI</p>
<p><img data-src="images/people/NoirritChandra.jpg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Chandra* and Sitek* et al.&nbsp;(2024 <em>Imaging Neuro</em>)</p>
</div></aside></section>
<section id="how-are-the-auditory-structures-connected-functionally-1" class="slide level2 smaller" data-visibility="uncounted">
<h2>How are the auditory structures connected <strong>functionally</strong>?</h2>
<h4 id="extracting-the-pathway-partial-correlations-from-the-network-simple-correlations-1">Extracting the <em>pathway</em> (partial correlations) from the <em>network</em> (simple correlations)</h4>
<div class="{columns}">
<div class="column" style="width:30%;">
<p><img data-src="images/ChandraSitek/FAC_fig-2_regions.png"></p>
</div><div class="column" style="width:70%;">
<p><img data-src="images/ChandraSitek/composite_Slide2.png"></p>
</div></div>
<p>7T Human Connectome Project (106 participants) resting state <strong>functional</strong> MRI</p>
<p><img data-src="images/people/NoirritChandra.jpg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Chandra* and Sitek* et al.&nbsp;(2024 <em>Imaging Neuro</em>)</p>
</div></aside></section></section>
<section id="section" class="title-slide slide level1 center">
<h1></h1>

</section>

<section>
<section id="auditory-categorization-in-the-human-brain" class="title-slide slide level1 center">
<h1>Auditory categorization in the human brain</h1>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-do-we-learn-new-sensory-categories" class="slide level2">
<h2>How do we learn new sensory categories?</h2>
<div class="quarto-layout-panel" data-layout="[70,30]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 70.0%;justify-content: flex-start;">
<ul>
<li class="fragment"><strong>Dorsal striatum</strong> contribute to learning new categories thanks to its many-to-one projections from <strong>distributed cortical networks</strong> that subserve:
<ul>
<li class="fragment">motor planning</li>
<li class="fragment"><strong>task-relevant sensory processing</strong></li>
<li class="fragment"><strong>feedback processing</strong></li>
<li class="fragment">decision-making</li>
</ul></li>
<li class="fragment">Dorsal striatum involved in auditory category learning tasks using fMRI (Feng et al., 2019; Lim et al., 2019; Yi et al., 2016)
<ul>
<li class="fragment">What <strong>anatomical pathways</strong> that connect the human auditory system to the striatum?</li>
<li class="fragment">How do <em>subdivisions</em> of dorsal striatum <strong>functionally contribute</strong> to category learning?</li>
</ul></li>
</ul>
</div>
<div class="quarto-layout-cell" style="flex-basis: 30.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Lim_striatum-schematic.jpg"></p>
<figcaption>Lim et al., 2014</figcaption>
</figure>
</div>
</div>
</div>
</div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>This work is actively supported by K01-DC019421 (PI: Sitek)</p>
</div></aside></section>
<section id="auditory-striatal-pathways-in-non-human-primates" class="slide level2">
<h2>Auditory-striatal pathways in non-human primates</h2>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/YeterianPandya1997.png" height="800"></p>
<figcaption>Macaque (Yeterian &amp; Pandya 1998)</figcaption>
</figure>
</div>
</div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>

</div></aside></section>
<section id="auditory-striatal-pathways-in-the-human-brain" class="slide level2">
<h2>Auditory-striatal pathways in the human brain</h2>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek2025_categorization/Sitek_tractography_streamlines.png" height="800"></p>
<figcaption>Sitek et al.&nbsp;(in revision)</figcaption>
</figure>
</div>
</div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Human Connectome Project 7T diffusion-weighted MRI dataset (n = 100)</p>
</div></aside></section>
<section id="similar-connectivity-patterns-in-humans-and-macaques" class="slide level2">
<h2>Similar connectivity patterns in humans and macaques</h2>
<div class="quarto-layout-panel" data-layout="[30,70]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 30.0%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/YeterianPandya1997.png" height="600"></p>
<figcaption>Macaque (Yeterian &amp; Pandya 1998)</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 70.0%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_corticostriatal_endpoints.png" height="750"></p>
<figcaption>Human (Sitek et al.&nbsp;2022 preprint, in revision)</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>

</div></aside></section>
<section id="how-do-humans-learn-new-sensory-categories" class="slide level2 smaller">
<h2>How do humans learn new sensory categories?</h2>
<div class="quarto-layout-panel" data-layout="[30, 35, 35]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 30.0%;justify-content: flex-start;">
<ul>
<li class="fragment">Auditory category learning task with Mandarin tone stimuli<sup>1</sup></li>
<li class="fragment">12 <strong>non</strong>-Mandarin-speaking participants (18–30 years old)</li>
<li class="fragment">7 Tesla high resolution functional MRI (1.5 mm isotropic vixels)</li>
</ul>
</div>
<div class="quarto-layout-cell" style="flex-basis: 35.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek2025_categorization/Sitek_Fig2_spect.png" class="fragment quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 35.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek2025_categorization/Sitek_Fig2_exp.png" class="fragment quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
</div>
</div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>

</div><ol class="aside-footnotes"><li id="fn1"><p>Yi 2016; Reetzke 2018; Feng 2019; …</p></li></ol></aside></section>
<section id="successful-learning-of-new-auditory-categories-in-mri" class="slide level2">
<h2>Successful learning of new auditory categories in MRI</h2>
<p><img data-src="images/Sitek2025_categorization/behav_learning-stage_subp-1.svg" class="fragment" height="900"></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in revision)</p>
</div></aside></section>
<section id="successful-learning-of-new-auditory-categories-in-mri-1" class="slide level2" data-visibility="uncounted">
<h2>Successful learning of new auditory categories in MRI</h2>
<p><img data-src="images/Sitek2025_categorization/behav_learning-stage_subp-1-2.svg" height="900"></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in revision)</p>
</div></aside></section>
<section id="successful-learning-of-new-auditory-categories-in-mri-2" class="slide level2" data-visibility="uncounted">
<h2>Successful learning of new auditory categories in MRI</h2>
<p><img data-src="images/Sitek2025_categorization/Sitek_beh_learning-stage.svg" height="900"></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in revision)</p>
</div></aside></section>
<section id="auditory-fmri-responses-to-sound-presentation" class="slide level2">
<h2>Auditory fMRI responses to sound presentation</h2>
<p><img data-src="images/Sitek2025_categorization/Sitek_sound-vs-baseline_slice.png" class="fragment" height="750"></p>

<aside class="notes">
<p>Sound responses: everything significant except for ParsTri</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in revision)</p>
</div></aside></section>


<section id="fmri-responses-to-feedback-correct-vs.-wrong" class="slide level2">
<h2>fMRI responses to feedback (“correct” vs.&nbsp;“wrong”)</h2>
<div class="columns">
<div class="column fragment" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek2025_categorization/Sitek_feedback_striatal_all-runs.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div><div class="column fragment" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek2025_categorization/Sitek_feedback_striatal_final-vs-early.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<div class="fragment">
<h4 id="striatum-feedback-responses">Striatum feedback responses</h4>
<ul>
<li>All regions showed positive responses in <em>early</em> learning stage</li>
<li>But only <strong>anterior putamen</strong> <em>maintained</em> positive responses across all runs</li>
<li>Only <strong>anterior caudate</strong> <em>significantly decreased</em> responses from early to final learning stages</li>
</ul>
</div>

<aside class="notes">
<ul>
<li>Sound responses: everything significant except for ParsTri</li>
<li>Stronger responses <em>overall</em> in early vs.&nbsp;final learning stages (runs)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in revision)</p>
</div></aside></section>
<section id="auditory-categorization-in-the-human-brain-1" class="slide level2">
<h2>Auditory categorization in the human brain</h2>
<div class="fragment">
<h4 id="we-identified-putative-corticostriatal-pathways-for-auditory-decision-making">We identified putative cortico–striatal pathways for auditory decision-making</h4>
<ul>
<li>Primary/secondary auditory cortex connects more strongly with <em>posterior</em> dorsal striatum</li>
<li>Non-invasive human connectivity is similar to invasive tracing in non-human primates (Yeterian &amp; Pandya 1998)</li>
</ul>
</div>
<div class="fragment">
<h4 id="dynamics-of-learning-and-categorization-in-dorsal-striatum">Dynamics of learning and categorization in dorsal striatum</h4>
<h4 id="when-presented-with-feedback">When presented with <strong>feedback</strong>:</h4>
<ul>
<li><strong>Anterior caudate</strong> responds highest early on</li>
<li><strong>Anterior putamen</strong> responds across learning stages</li>
</ul>
</div>
<h3 class="fragment" id="putamen-and-caudate-subdivisions-have-unique-functional-and-connectivity-profiles">Putamen and caudate <em>subdivisions</em> have unique functional and connectivity profiles</h3>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in revision)</p>
</div></aside></section></section>
<section id="section-1" class="title-slide slide level1 center">
<h1></h1>

</section>

<section>
<section id="auditorymotor-interactions-across-the-auditory-pathway" class="title-slide slide level1 center">
<h1>Auditory–motor interactions across the auditory pathway</h1>
<aside class="notes">
<p>So far I’ve focused on the basics: where are human auditory structures, and how are they connected. Ultimately, we want to <em>use</em> these approaches to learn more about the <em>function</em> of the human brain <em>in action</em>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="human-speech-and-auditory-feedback-processing" class="slide level2">
<h2>Human speech and auditory feedback processing</h2>
<div class="columns">
<div class="column fragment">
<h4 id="suppressed-cortical-response-to-own-voice-while-speaking-houde-jordan-2002">Suppressed cortical response to own voice while speaking (Houde &amp; Jordan 2002)</h4>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/HoudeJordan2002.png" class="quarto-figure quarto-figure-center" height="700"></p>
</figure>
</div>
</div><div class="column fragment">
<h4 id="less-suppression-when-our-own-speech-is-variable-sitek-et-al.-2013">Less suppression when our own speech is <em>variable</em> (Sitek et al.&nbsp;2013)</h4>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek2013_Fig1.png" class="quarto-figure quarto-figure-center" height="700"></p>
</figure>
</div>
</div></div>

<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>This work is actively supported by R21-DC022906 (PI: Sitek).</p>
</div></aside></section>

<section id="studying-the-human-subcortical-auditory-system-with-eeg" class="slide level2">
<h2>Studying the human subcortical auditory system with EEG</h2>
<h4 id="the-scalp-recorded-frequency-following-response-ffr-shows-the-fidelity-of-incoming-sound-encoding">The scalp-recorded frequency-following response (FFR) shows the fidelity of incoming sound encoding</h4>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Coffey2018_Fig1a.png" class="fragment quarto-figure quarto-figure-center"></p>
</figure>
</div>

<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Coffey et al.&nbsp;(2018)</p>
</div></aside></section>
<section id="where-are-motor-signals-integrated-subcortically" class="slide level2">
<h2><em>Where</em> are motor signals integrated? Subcortically?</h2>
<p><img data-src="images/people/GabbyButler.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>
<div class="quarto-layout-panel" data-layout="[60,40]">
<div class="quarto-layout-row">
<div class="column fragment quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<ul>
<li>If integration is <strong>subcortical</strong>:
<ul>
<li>Expect to see <strong>FFR</strong> differences between <em>self-generated</em> and <em>passive</em> sound</li>
</ul></li>
<li>Recorded FFRs to /da/ stimulus
<ul>
<li><em>Active</em> condition: press a button to generate a sound</li>
<li><em>Passive</em> condion: passive presentation of the sound</li>
</ul></li>
<li>Collected data from 33 normal-hearing adults</li>
</ul>
</div><div class="column fragment quarto-layout-cell" style="flex-basis: 40.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/Butler_etal_2025/Butler_EEG.png" class="quarto-figure quarto-figure-left"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Butler_etal_2025/Butler_stimulus.png" class="quarto-figure quarto-figure-center" height="250"></p>
</figure>
</div>
</div></div>
</div>

<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Butler, …, Sitek (in prep; SNL 2025)</p>
</div></aside></section>
<section id="active-and-passive-evoked-responses" class="slide level2">
<h2>Active and passive evoked responses</h2>
<p><img data-src="images/people/GabbyButler.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>
<div class="columns">
<div class="column fragment">
<h4 id="brainstem-frequency-following-response">Brainstem frequency-following response</h4>
<p><img data-src="images/Butler_etal_2025/Butler_FFR_waveform.png" height="700"></p>
</div><div class="column fragment">
<h4 id="cortical-evoked-response">Cortical evoked response</h4>
<p><img data-src="images/Butler_etal_2025/Butler_cortical_waveform.png" height="700"></p>
</div></div>

<aside class="notes">
<p>FFR spectrograms don’t vary between conditions; neither do power or latency-to-first-peak</p>
<p>All of which <em>do</em> vary in cortical responses</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Butler, …, Sitek (in prep; SNL 2025)</p>
</div></aside></section>


<section id="where-are-motor-signals-integrated-subcortically-1" class="slide level2">
<h2><em>Where</em> are motor signals integrated? Subcortically?</h2>
<p><img data-src="images/people/GabbyButler.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>
<h4 id="brainstem-frequency-following-response-ffr-shows-the-same-sound-encoding-when-a-sound-is-self-generated-or-passively-presented">Brainstem frequency-following response (FFR) shows the same sound encoding when a sound is self-generated or passively presented</h4>
<ul>
<li class="fragment">No <strong>brainstem FFR</strong> differences, despite <strong>cortical</strong> evoked response differences</li>
<li class="fragment"><em>Motor signals unlikely to attenuate earliest central auditory signals</em></li>
<li class="fragment">Next steps:
<ul>
<li class="fragment"><strong>Source localization</strong> of FFR generators (ECR R21 project)</li>
<li class="fragment"><strong>Cortical layer-specific</strong> feedback localization with 7T fMRI (planned R01)</li>
</ul></li>
</ul>

<aside class="notes">
<p>If integration is subcortical, would expect to see FFR differences between self-generated vs.&nbsp;passive sound</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Butler, …, Sitek (in prep; SNL 2025)</p>
</div></aside></section></section>
<section>
<section id="where-were-going-next" class="title-slide slide level1 center">
<h1>Where we’re going next</h1>

</section>
<section id="future-research-directions" class="slide level2">
<h2>Future research directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_future-overview/Slide1.png" class="fragment quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
<aside class="notes">
<p>Sensory <em>and motor speech</em> learning - Role of striatum <em>across</em> communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01</p>
<p>Hearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21</p>
<p>Translational insights - Adapting multi-echo fMRI to better understand <strong>hearing loss in middle age</strong> (Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>) - Auditory cortical mechanisms supporting compensation in <strong>children who stutter</strong> (Sitek et al., SNL 2025, <em>in prep.</em>) - Network connectivity supporting <strong>aphasia</strong> recovery</p>
<ul>
<li>ME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke</li>
<li>Stuttering:</li>
<li>Cochlear implants:</li>
<li>Aphasia</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="future-research-directions-1" class="slide level2" data-visibility="uncounted">
<h2>Future research directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_future-overview/Slide2.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
<aside class="notes">
<p>Sensory <em>and motor speech</em> learning - Role of striatum <em>across</em> communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01</p>
<p>Hearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21</p>
<p>Translational insights - Adapting multi-echo fMRI to better understand <strong>hearing loss in middle age</strong> (Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>) - Auditory cortical mechanisms supporting compensation in <strong>children who stutter</strong> (Sitek et al., SNL 2025, <em>in prep.</em>) - Network connectivity supporting <strong>aphasia</strong> recovery</p>
<ul>
<li>ME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke</li>
<li>Stuttering:</li>
<li>Cochlear implants:</li>
<li>Aphasia</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="future-research-directions-2" class="slide level2" data-visibility="uncounted">
<h2>Future research directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_future-overview/Slide3.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
<aside class="notes">
<p>Sensory <em>and motor speech</em> learning - Role of striatum <em>across</em> communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01</p>
<p>Hearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21</p>
<p>Translational insights - Adapting multi-echo fMRI to better understand <strong>hearing loss in middle age</strong> (Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>) - Auditory cortical mechanisms supporting compensation in <strong>children who stutter</strong> (Sitek et al., SNL 2025, <em>in prep.</em>) - Network connectivity supporting <strong>aphasia</strong> recovery</p>
<ul>
<li>ME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke</li>
<li>Stuttering:</li>
<li>Cochlear implants:</li>
<li>Aphasia</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="future-research-directions-3" class="slide level2" data-visibility="uncounted">
<h2>Future research directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_future-overview/Slide4.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
<aside class="notes">
<p>Sensory <em>and motor speech</em> learning - Role of striatum <em>across</em> communication functions - Implications for stuttering, Parkinson’s, other communication disorders - R01 follow-up to K01</p>
<p>Hearing our own speech - Layer-specific auditory processing of self-produced sounds (7T fMRI) - MEG? Intracortical recordings? - Implications for stuttering, autism, cerebellar stroke and ataxia of speech - R01 follow-up to R21</p>
<p>Translational insights - Adapting multi-echo fMRI to better understand <strong>hearing loss in middle age</strong> (Medina, Sitek, et al., <em>submitted</em>; Medina, …, Sitek, <em>in prep</em>) - Auditory cortical mechanisms supporting compensation in <strong>children who stutter</strong> (Sitek et al., SNL 2025, <em>in prep.</em>) - Network connectivity supporting <strong>aphasia</strong> recovery</p>
<ul>
<li>ME-fMRI: collaborators in physical movement sciences are using this approach to understand brainstem pathways in motor recovery from stroke</li>
<li>Stuttering:</li>
<li>Cochlear implants:</li>
<li>Aphasia</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="sensory-and-motor-speech-learning-shared-striatal-mechanisms" class="slide level2">
<h2>Sensory <em>and motor speech</em> learning: Shared striatal mechanisms?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li class="fragment">Dorsal striatum (caudate and putamen) is critical to auditory learning (Sitek et al., in revision) <em>and</em> motor learning</li>
<li class="fragment">Are the neural implementations shared across perceptual and motor learning <strong>in the context of speech and language</strong>?</li>
<li class="fragment">How are shared mechanisms affected in <em>stuttering</em>, <em>dyslexia</em>, or <em>Parkinson’s</em>, and can they <strong>inform therapeutic opportunities</strong>?</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Lim_striatum-schematic.jpg"></p>
<figcaption>Lim et al., 2014</figcaption>
</figure>
</div>
</div></div>
<aside class="notes">
<p>Stuttering Treatment implications Learning-based therapy, not just fluency shaping Emphasize rewarded, gradually stabilized speech patterns Closed-loop auditory reinforcement paradigms More targeted dopamine modulation (dose, timing, task-coupled) Neurostimulation aimed at striatal–SMA loops, not just cortex</p>
<p>Dyslexia Treatment implications Shift from pure phonics to reinforcement-based learning frameworks Use adaptive reward schedules to strengthen sound–action associations Predict differential benefit from procedural vs declarative training Early identification via auditory category learning tasks, not just phonological tests</p>
<p>Parkinson’s Treatment implications Therapy timed to dopaminergic state to optimize learning Use of external reinforcement and cueing to replace striatal learning Personalized speech therapy based on learning rate, not just severity Speech as a biomarker for basal ganglia learning capacity</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="hearing-our-own-speech-where-are-motor-signals-integrated-in-auditory-cortex" class="slide level2">
<h2>Hearing our own speech: <em>Where</em> are motor signals integrated in auditory cortex?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li class="fragment">Auditory cortex is a hub for motor integration</li>
<li class="fragment">But fMRI has shown <em>increased</em> BOLD to self-generated sounds, vs.&nbsp;<em>suppressed</em> M/EEG</li>
<li class="fragment">Are different <strong>laminar</strong> responses the explanation?</li>
</ul>
<h4 class="fragment" id="we-can-look-at-intra-cortical-circuits-with-ultra-high-field-7t-fmri">We can look at intra-cortical circuits with ultra-high field <strong>7T fMRI</strong></h4>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Behroozmand 2015_sp-gt-play_no-shift.png" height="150"></p>
<figcaption>Behroozmand et al.&nbsp;(2015)</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Reznik2014_Figure1a.png" height="150"></p>
<figcaption>Reznik et al.&nbsp;(2015)</figcaption>
</figure>
</div>
</div></div>

<aside class="notes">
<p>Behroozmand (2015) discussion para 2: &gt; When compared to rest, we found that during both speaking and playback conditions, the strongest activation in response to normal (no shift) and pitch-shifted vowel sound was observed within temporal lobe auditory cortices. This temporal lobe activation did not differ significantly for the speaking versus playback conditions. However, during speaking, we found significant BOLD activation increases in other sensory–motor areas including bilateral precentral gyrus, postcentral gyrus, anterior insula, SMA and IFG compared with playback. The speaking-induced BOLD response enhancement in these sensory–motor areas was not significantly modulated by the presence or absence of pitch-shift stimulus in the auditory feedback.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>

</div></aside></section>
<section id="hearing-our-own-speech-where-are-motor-signals-integrated-in-auditory-cortex-1" class="slide level2" data-visibility="uncounted">
<h2>Hearing our own speech: <em>Where</em> are motor signals integrated in auditory cortex?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>Auditory cortex is a hub for motor integration</li>
<li>But fMRI has shown <em>increased</em> BOLD to self-generated sounds, vs.&nbsp;<em>suppressed</em> M/EEG</li>
<li>Are different <strong>laminar</strong> responses the explanation?</li>
</ul>
<h4 id="we-can-look-at-intra-cortical-circuits-with-ultra-high-field-7t-fmri-1">We can look at intra-cortical circuits with ultra-high field <strong>7T fMRI</strong></h4>
<ul>
<li class="fragment"><strong>Cortical depth profile</strong> differences during self-generated vs.&nbsp;passive sound listening</li>
<li class="fragment">Higher increases at <strong>superficial</strong> cortical depths, suggesting increased <strong>corticocortical</strong> feedback</li>
<li class="fragment">Future work: Pinpointing feedback dysfunction in <em>stuttering</em>, <em>schizophrenia</em>, and other feedback processing disorders</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Behroozmand 2015_sp-gt-play_no-shift.png" height="150"></p>
<figcaption>Behroozmand et al.&nbsp;(2015)</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Reznik2014_Figure1a.png" height="150"></p>
<figcaption>Reznik et al.&nbsp;(2015)</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/selfgen.png" height="250"></p>
<figcaption>Sitek et al.&nbsp;(OHBM 2025)</figcaption>
</figure>
</div>
</div></div>

<aside class="notes">
<ul>
<li>Reproducible—same cortical depth effects in two acquisitions in the same participant</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>

</div></aside></section>
<section id="improving-clinical-translation-at-3t-with-multi-echo-fmri" class="slide level2">
<h2>Improving clinical translation at 3T with multi-echo fMRI</h2>
<p><img data-src="images/people/MichelleMedina.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>
<div class="columns">
<div class="column">
<div class="fragment">
<h4 id="multi-echo-fmri-improves-subcortical-and-cortical-fmri-sensitivity">Multi-echo fMRI improves subcortical (and cortical!) fMRI sensitivity</h4>
<ul>
<li>Typical fMRI uses one readout (“echo”)</li>
<li>But optimal echo time (TE) isn’t consistent across the brain</li>
<li>Multi-echo fMRI allows <em>optimal combination</em> of different TEs across the brain</li>
</ul>
</div>
<div class="fragment">
<h4 id="listening-task-in-3t-fmri">Listening task in 3T fMRI</h4>
<ul>
<li>14 participants</li>
<li>10 minutes of pop-song listening</li>
<li>3 participants returned for precision-mapping session</li>
<li>Multi-echo fMRI acquisition from UMinn CMRR</li>
</ul>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/multiecho-vs-singleecho.png"></p>
<figcaption>Dartmouth BIC</figcaption>
</figure>
</div>
</div></div>

<aside class="notes">
<p>So far, each of the results I’ve shown have used 7 Tesla MRI. These are becoming more prevalent, especially now that the Siemens Terra is approved by the FDA. But they’re still much less common than 3 Tesla MRIs. Fortunately, data acquisition protocols have improved sensitivty even at 3T, so that we can reliably identify auditory midbrain and thalamus.</p>
<ul>
<li>Multi-echo fMRI acquisition
<ul>
<li>Echo times = 13.40/39.5/65.6 ms</li>
<li>Repetition time = 2.2 s</li>
<li>Multiband factor = 2</li>
<li>Voxel size = 1.731×1.731×4 mm<sup>3</sup></li>
<li>Whole-brain coverage (44 slices, FOV=180mm)</li>
</ul></li>
<li>Multi-echo optimal combination + ICA noise removal (<code>tedana</code>)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Medina et al.&nbsp;(submitted preprint); Medina, …, Sitek (in prep.)</p>
</div></aside></section>


<section id="improved-precision-mapping-with-multi-echo-fmri" class="slide level2">
<h2>Improved precision mapping with multi-echo fMRI</h2>
<p><img data-src="images/people/MichelleMedina.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>
<div class="columns">
<div class="column fragment" style="width:55%;">
<h4 id="multi-echo-requires-less-scan-time-to-identify-auditory-brainstem">Multi-echo requires less scan time to identify auditory brainstem</h4>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Medina2025/Medina_Figure4b_bstem.png" class="quarto-figure quarto-figure-center" height="750"></p>
</figure>
</div>
</div><div class="column fragment" style="width:45%;">
<h4 id="subcortical-activations-are-stronger-with-multi-echo-than-single-echo-fmri">Subcortical activations are stronger with multi-echo than single-echo fMRI</h4>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Medina2025/Medina_Figure4a.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>

<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Medina et al.&nbsp;(submitted preprint); Medina, …, Sitek (in prep.)</p>
</div></aside></section>
<section id="improving-brainstem-sensitivity-at-3t-with-multi-echo-fmri-1" class="slide level2">
<h2>Improving brainstem sensitivity at 3T with multi-echo fMRI</h2>
<h3 id="future-applications-auditory-processing-across-the-lifespan">Future applications: Auditory processing across the lifespan</h3>
<div class="columns">
<div class="column fragment" style="width:60%;">
<h4 id="auditory-processing-changes-throughout-adulthood">Auditory processing changes throughout adulthood</h4>
<ul>
<li>How does speech-in-noise processing change in middle age and beyond?</li>
<li>What neural patterns predict later cochlear implant success?</li>
</ul>
<div class="fragment">
<h4 id="speech-processing-in-the-developing-brain">Speech processing in the developing brain</h4>
<ul>
<li>How do children make auditory category decisions, and how are they affected by noise?</li>
<li>What compensatory neural pathways are available to children with developmental communication differences?</li>
</ul>
</div>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/imag_a_00426_fig4.jpeg" height="800"></p>
<figcaption>Moser et al.&nbsp;(2025)</figcaption>
</figure>
</div>
</div></div>
<aside class="notes">
<p>Moser et al.&nbsp;(2025): https://doi.org/10.1162/imag_a_00426 “The sample consists of one adult (PA001) and two children (PC001 and PC002; age 10) enrolled at the University of Minnesota (UMN), and one adult (PA002) and three healthy neonates enrolled at Washington University in St.&nbsp;Louis (WashU), ages 28 days (43 weeks postmenstrual age (wPMA); PB004), 12 days (41 wPMA; PB005), and 13 days (41 wPMA; PB001)”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="a-systems-level-approach-to-human-speech-neuroscience-3" class="slide level2">
<h2>A systems-level approach to human speech neuroscience</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_overview/Slide3.png" class="quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>
</section>
<section id="acknowledgments" class="slide level2 smaller">
<h2>Acknowledgments</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h4 id="soundbrain-lab">SoundBrain Lab</h4>
<ul>
<li><strong>Bharath Chandrasekaran</strong>, Jacie McHaney, Kailyn McFarlane</li>
<li>Nike Gnanateja (now UW Madison CSD)</li>
<li>Casey Roark (now U New Hampshire Psychology)</li>
</ul>
<p><img data-src="images/people/SoundBrain-lab-current-members-and-alum_FFR-workshop-2024-550x310.jpg" height="500"></p>
</div><div class="column" style="width:50%&quot;;">
<p><strong>Northwestern</strong>: Molly Bright, <strong>Michelle Medina</strong> (<em>BME PhD student</em>), <strong>Gabby Butler</strong> (<em>Cog Sci UG honors student</em>), Max Chen (<em>Cog Sci/Comp Sci undergrad</em>)</p>
<p><strong>UT Austin collaborators</strong>: Abhra Sarkar, Noirrit Chandra (<em>UT Dallas</em>), Blake Moya (<em>industry</em>)</p>
<p><strong>Pitt</strong>: Jay Bohland, Mandy Hampton Wray</p>
<p><strong>Harvard/MIT</strong>: Satra Ghosh (<em>PhD advisor</em>)</p>
<h3 id="active-funding-and-support">Active funding and support</h3>
<ul>
<li>K01 DC019421 (2023–2027)</li>
<li>R21 DC022906 (2025–2028)</li>
<li>R01 DC020963 (2024–2027; PI: Bohland)</li>
</ul>
</div></div>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section id="thank-you" class="title-slide slide level1 center" data-background-image="./images/KevinSitek_postmortem-human-brainstem_auditory-tractography.png" data-background-opacity="0.25" data-background-size="contain">
<h1>Thank you!</h1>

</section>

<section>
<section id="extra-slides" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Extra slides</h1>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-is-the-brainstem-supplied-oxygen" class="slide level2" data-visibility="uncounted">
<h2>How is the brainstem supplied oxygen?</h2>
<p><img data-src="images/Xu2025/vasculature_T2w.png" class="absolute" style="top: 10px; right: 10px; width: 300px; height: 300px; "></p>
<div class="quarto-layout-panel" data-layout="[40,20,40]">
<div class="quarto-layout-row quarto-layout-valign-center">
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Xu2025/vasculature_Duvernoy.png" height="750"></p>
<figcaption>Vessel ink staining (Duvernoy 1978)</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Xu2025/vasculature_MIP.png" height="750"></p>
<figcaption>T2*-w MRI max. intensity projection</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<video id="video_shortcode_videojs_video4" width="800%" height="500%" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="images/Xu2025/S64520_m0_SLA_booster_result_bg-white.mp4"></video>
</div>
</div>
</div>
<p><img data-src="images/people/MarshallXu.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p>Video: 1920x1088</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Xu et al.&nbsp;(ISMRM 2025); Xu, …, S. Bollmann<em>, Sitek</em> (in prep.)</p>
</div></aside></section>
<section id="how-is-the-brainstem-supplied-oxygen-1" class="slide level2" data-visibility="uncounted">
<h2>How is the brainstem supplied oxygen?</h2>
<video id="video_shortcode_videojs_video5" width="1920" height="1088" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="images/Xu2025/S64520_m0_SLA_booster_result_bg-white.mp4"></video>
</section>
<section id="finger-motor-representation-in-the-human-brain" class="slide level2" data-visibility="uncounted">
<h2>Finger motor representation in the human brain</h2>
<div class="quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/Moya_etal_2025/dmncADL.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/Moya_etal_2025/dmncADR.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/Moya_etal_2025/dmncPVR.png"></p>
</div>
</div>
</div>
<p>Posterior mean dominance greater than 25% across voxels for the <span style="color:red;">right index (red)</span>, <span style="color:blue;">left index (blue)</span>, and <span style="color:green;">middle fingers (green)</span>.</p>
<p><img data-src="images/people/BlakeMoya.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>

<aside class="notes">
<p>Moya et al. Results for the fingertip mapping study:<br>
Fingertip dominance across the investigated regions. Posterior mean dominance greater than <span class="math inline">\(25\%\)</span> is shown across voxels for the right index finger (red), left index (blue), and middle fingers (green) based on the estimated partition structures and the estimated effect intensities.<br>
Colors blend when two or more fingers exhibit greater than <span class="math inline">\(25\%\)</span> dominance probabilities at the same location, showing areas of competing dominance for the right index and either middle finger (yellow), left index and either middle finger (cyan), and the two index fingers (purple).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Moya et al.&nbsp;(in prep.)</p>
</div></aside></section>
<section id="the-developing-auditory-system" class="slide level2" data-visibility="uncounted">
<h2>The developing auditory system</h2>
<h4 id="how-do-we-learn-to-hear-in-noisy-environments">How do we learn to hear in noisy environments?</h4>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li class="fragment">Adults: maturation of speech network<sup>1</sup> + compensatory networks<sup>2</sup></li>
<li class="fragment">Children: fine-tuning speech network + undeveloped frontal networks</li>
<li class="fragment">Collected syllable-in-noise task fMRI at 3T in 35 typically developing kids
<ul>
<li class="fragment">5 speech-shaped noise contexts: Quiet and SNR = +8, 0, -2, and -6</li>
<li class="fragment">Task: identify which of 4 syllables were presented</li>
</ul></li>
</ul>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Cocktail-party.jpg"></p>
<figcaption>via The Telegraph</figcaption>
</figure>
</div>
</div>
</div>
</div>

<aside class="notes">
<p>SSP</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in prep.; SNL 2025)</p>
</div><ol class="aside-footnotes"><li id="fn4"><p>Du et al.&nbsp;(2014)</p></li><li id="fn5"><p>Vaden et al.&nbsp;(2013); Eckert et al.&nbsp;(2016)</p></li></ol></aside></section>
<section id="the-developing-auditory-system-speech-in-quiet-vs.-baseline-fmri-contrast" class="slide level2" data-visibility="uncounted">
<h2>The developing auditory system: Speech-in-quiet vs.&nbsp;baseline fMRI contrast</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_SSP_quiet-gt-baseline.png" class="fragment quarto-figure quarto-figure-center"></p>
</figure>
</div>

<aside class="notes">
<p>SSP</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in prep.; SNL 2025)</p>
</div></aside></section>
<section id="the-developing-auditory-system-speech-in-quiet-vs.--6-db-snr" class="slide level2" data-visibility="uncounted">
<h2>The developing auditory system: Speech-in-quiet vs.&nbsp;-6 dB SNR</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_SSP_quiet-gt-n6.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>

<aside class="notes">
<p>SSP</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in prep.; SNL 2025)</p>
</div></aside></section>
<section id="systems-for-speech-in-noise-processing-are-actively-developing-in-adolescents" class="slide level2" data-visibility="uncounted">
<h2>Systems for speech-in-noise processing are actively developing in adolescents</h2>
<div class="quarto-layout-panel" data-layout="[40,60]">
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<ul>
<li class="fragment">Children activate broad canonical auditory and language regions more strongly in clear speech compared to noisy stimuli</li>
<li class="fragment">No evidence that they utilize compensatory motor and prefrontal regions seen in adults</li>
<li class="fragment">Investigating task-relevant <em>representations</em> in development</li>
<li class="fragment">Currently collecting data in <strong>children who stutter</strong></li>
</ul>
</div>
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Sitek_SSP_quiet-gt-n6.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
</div>
</div>

<aside class="notes">
<p>SSP</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(in prep.; SNL 2025);</p>
<p>Hampton-Wray R01DC019904</p>
</div></aside></section>
<section id="multi-echo-fmri-improves-group-level-sensitivity-at-3t-1" class="slide level2" data-visibility="uncounted">
<h2>Multi-echo fMRI improves group-level sensitivity at 3T</h2>
<p><img data-src="images/people/MichelleMedina.jpeg" class="absolute" style="bottom: 10px; right: 10px; width: 200px; height: 200px; "></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Medina2025/Medina_Figure1.png" class="fragment quarto-figure quarto-figure-center" height="900"></p>
</figure>
</div>

<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Medina et al.&nbsp;(submitted preprint); Medina, …, Sitek (in prep.)</p>
</div></aside></section>

</section>
<section>


<section id="greater-self-generated-vs.-passive-fmri-responses-in-a-single-participant-across-replications" class="slide level2" data-visibility="uncounted">
<h2>Greater self-generated vs.&nbsp;passive fMRI responses in a single participant across replications</h2>
<div class="columns">
<div class="column fragment">
<p><img data-src="images/Sitek_MIS_slices_contrast-listen.png"></p>
</div><div class="column fragment">
<p><img data-src="images/Sitek_MIS_slices_contrast-selfgen-vs-listen.png"></p>
</div></div>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Sitek et al.&nbsp;(OHBM 2025)</p>
</div></aside></section>
<section id="stronger-self-generated-vs.-passive-sound-responses-in-superficial-auditory-cortex" class="slide level2" data-visibility="uncounted">
<h2>Stronger self-generated (vs.&nbsp;passive) sound responses in superficial auditory cortex</h2>
<p><img data-src="images/7T_replication.png"></p>

<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


<aside><div>
<p>Sitek et al.&nbsp;(OHBM 2025)</p>
</div></aside></section></section>

    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>https://sitek.github.io/</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    <script>videojs(video_shortcode_videojs_video2);</script>
    <script>videojs(video_shortcode_videojs_video3);</script>
    <script>videojs(video_shortcode_videojs_video4);</script>
    <script>videojs(video_shortcode_videojs_video5);</script>
    

</body></html>